{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS211: Data Privacy\n",
    "## In-Class Exercise, week of 10/31/2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2801/3054158115.py:6: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use('seaborn-whitegrid')\n"
     ]
    }
   ],
   "source": [
    "# Load the data and libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "def laplace_mech(v, sensitivity, epsilon):\n",
    "    return v + np.random.laplace(loc=0, scale=sensitivity / epsilon)\n",
    "\n",
    "def gaussian_mech(v, sensitivity, epsilon, delta):\n",
    "    return v + np.random.normal(loc=0, scale=sensitivity * np.sqrt(2*np.log(1.25/delta)) / epsilon)\n",
    "\n",
    "def gaussian_mech_vec(vec, sensitivity, epsilon, delta):\n",
    "    return [v + np.random.normal(loc=0, scale=sensitivity * np.sqrt(2*np.log(1.25/delta)) / epsilon)\n",
    "            for v in vec]\n",
    "\n",
    "def pct_error(orig, priv):\n",
    "    return np.abs(orig - priv)/orig * 100.0\n",
    "\n",
    "# adult = pd.read_csv('https://github.com/jnear/cs211-data-privacy/raw/master/homework/adult_with_pii.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data files\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import io\n",
    "\n",
    "url_x = 'https://github.com/jnear/cs211-data-privacy/raw/master/slides/adult_processed_x.npy'\n",
    "url_y = 'https://github.com/jnear/cs211-data-privacy/raw/master/slides/adult_processed_y.npy'\n",
    "\n",
    "with urllib.request.urlopen(url_x) as url:\n",
    "    f = io.BytesIO(url.read())\n",
    "X = np.load(f)\n",
    "\n",
    "with urllib.request.urlopen(url_y) as url:\n",
    "    f = io.BytesIO(url.read())\n",
    "y = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X is the same as adult.csv but setup nicley for machine learning\n",
    "# Everything is a number, categorical values are one-hot encoded \n",
    "#     To one hot encode something, create an n length vector, where n is the # of possible values \n",
    "#     Set all to 0 except the one for the selected\n",
    "# One hot encoding expands the # of coumns 19 -> 104"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and test set sizes: 36176 9044\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and test sets\n",
    "training_size = int(X.shape[0] * 0.8)\n",
    "\n",
    "x_train = X[:training_size]\n",
    "x_test = X[training_size:]\n",
    "\n",
    "y_train = y[:training_size]\n",
    "y_test = y[training_size:]\n",
    "\n",
    "print('Train and test set sizes:', len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "Using scikit-learn, train a logistic regression model on the training data loaded above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6eeb7ec9241a2a7c54c5594dc4d77c69",
     "grade": true,
     "grade_id": "cell-32c8bf5cd1ba5719",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model coefficients: [ 4.78139205e-01 -1.79956514e-01 -3.40239314e-02  6.84210447e-02\n",
      " -5.91027836e-01 -3.66111064e-01 -1.06083247e+00 -6.69749843e-01\n",
      " -6.36897045e-01 -4.60622052e-01 -5.10623615e-01 -3.97837711e-01\n",
      " -7.57652238e-01 -7.81287024e-01  6.35764981e-02  1.18067100e-01\n",
      "  5.10746634e-01  1.00307693e+00 -1.12284805e-01  7.38198230e-01\n",
      " -1.18443431e+00  1.28199985e+00  1.10331842e-01 -8.97901491e-01\n",
      "  1.50203219e+00  1.25193383e+00 -5.83474111e-01 -1.31380633e+00\n",
      " -8.89748113e-01 -7.54427536e-01 -5.67454198e-02  5.14477437e-02\n",
      " -8.14655572e-04  7.21850375e-01 -8.96540282e-01 -6.94306000e-01\n",
      " -3.23897413e-01 -9.41104911e-01 -1.09691775e+00  4.72866034e-01\n",
      "  4.76951082e-01  2.21548702e-01  5.09549054e-01 -1.29278122e-01\n",
      " -3.74278495e-01  1.79089784e-03 -7.74204436e-01 -1.05097080e+00\n",
      " -1.90670650e-01  7.02941924e-01 -5.02470396e-01 -4.51253423e-02\n",
      " -4.88120092e-01 -4.18069074e-01 -2.31606658e-01 -1.17528743e+00\n",
      " -5.10104136e-01  8.94575562e-01  6.12555630e-01 -2.84252476e-01\n",
      " -1.27129583e+00  1.13968510e-01 -4.79613724e-01 -2.56513394e-01\n",
      " -1.84743502e-01  6.39708769e-01  8.82889354e-01  1.58510142e-02\n",
      "  4.91347342e-02  5.38231592e-02  4.10225183e-01 -1.64996744e-02\n",
      "  7.53301606e-02 -2.71859583e-01  5.79569482e-01  1.69473744e-02\n",
      "  2.56130594e-01  7.50864074e-01  7.69351798e-01  2.66356984e-01\n",
      " -8.56153442e-02 -7.43856348e-01 -5.85219392e-01 -3.65806757e-01\n",
      " -3.50565315e-01 -5.70997814e-01  2.68340246e-01  3.62079398e-02\n",
      "  3.74297028e-01 -2.17801868e-01 -9.50750647e-01 -6.53152581e-01\n",
      " -1.22541038e-01 -6.43284213e-01 -4.87927940e-01  3.02748842e-01\n",
      " -9.45922531e-01  4.33951971e-01  2.26093070e+00  1.02667686e+00\n",
      "  1.99438299e+00  1.86494543e+01  2.57235166e+00  2.74279370e+00]\n",
      "Model accuracy: 0.8447589562140646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/semaj/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "def train_model():\n",
    "    model = LogisticRegression().fit(x_train, y_train)\n",
    "    return model\n",
    "\n",
    "model = train_model()\n",
    "print('Model coefficients:', model.coef_[0])\n",
    "print('Model accuracy:', np.sum(model.predict(X_test) == y_test)/X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Implement the *average gradient* of the loss below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The loss function measures how good our model is. The training goal is to minimize the loss.\n",
    "# This is the logistic loss function.\n",
    "def loss(theta, xi, yi):\n",
    "    exponent = - yi * (xi.dot(theta))\n",
    "    return np.log(1 + np.exp(exponent))\n",
    "\n",
    "# This is the gradient of the logistic loss\n",
    "# The gradient is a vector that indicates the rate of change of the loss in each direction\n",
    "def gradient(theta, xi, yi):\n",
    "    exponent = yi * (xi.dot(theta))\n",
    "    return - (yi*xi) / (1+np.exp(exponent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab7d67d24660b6cbf040bc661971aaa0",
     "grade": true,
     "grade_id": "cell-ace29743234ed3f6",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def avg_grad(theta, x, y):\n",
    "    gradients = [gradient(theta, xi, yi) for xi, yi in zip(x, y)]\n",
    "    return np.mean(gradients, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Use the average gradient from above to implement a gradient descent algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c4850cab1fb79077d710818b58adf4fc",
     "grade": true,
     "grade_id": "cell-87483deb56e7ce88",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'L2_clip' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [24], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m         theta \u001b[38;5;241m=\u001b[39m theta \u001b[38;5;241m-\u001b[39m eta \u001b[38;5;241m*\u001b[39m noisy_grad\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m theta\n\u001b[0;32m---> 15\u001b[0m theta \u001b[38;5;241m=\u001b[39m \u001b[43mgradient_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m theta\n",
      "Cell \u001b[0;32mIn [24], line 8\u001b[0m, in \u001b[0;36mgradient_descent\u001b[0;34m(iterations)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iterations):\n\u001b[1;32m      7\u001b[0m     grads \u001b[38;5;241m=\u001b[39m [gradient(theta, x, y) \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(x_train, y_train)]\n\u001b[0;32m----> 8\u001b[0m     clipped_grads \u001b[38;5;241m=\u001b[39m [L2_clip(g, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m grads]\n\u001b[1;32m      9\u001b[0m     grad_sum \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(clipped_grads, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# this is the gradient update  rule \u001b[39;00m\n",
      "Cell \u001b[0;32mIn [24], line 8\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iterations):\n\u001b[1;32m      7\u001b[0m     grads \u001b[38;5;241m=\u001b[39m [gradient(theta, x, y) \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(x_train, y_train)]\n\u001b[0;32m----> 8\u001b[0m     clipped_grads \u001b[38;5;241m=\u001b[39m [\u001b[43mL2_clip\u001b[49m(g, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m grads]\n\u001b[1;32m      9\u001b[0m     grad_sum \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(clipped_grads, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# this is the gradient update  rule \u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'L2_clip' is not defined"
     ]
    }
   ],
   "source": [
    "def gradient_descent(iterations):\n",
    "    # start out iwt theta = all zeros\n",
    "    theta = np.zeros(x_train.shape[1])\n",
    "    eta = 1\n",
    "    # for `iterations` iterations, update theta by adding the negation for the gradient\n",
    "    for _ in range(iterations):\n",
    "        grads = [gradient(theta, x, y) for x, y in zip(x_train, y_train)]\n",
    "        clipped_grads = [L2_clip(g, 1) for g in grads]\n",
    "        grad_sum = np.sum(clipped_grads, axis=0)\n",
    "        # this is the gradient update  rule \n",
    "        noisy_grad = laplace_mech_vec(grad, 1, epsilon)\n",
    "        theta = theta - eta * noisy_grad\n",
    "    return theta\n",
    "        \n",
    "theta = gradient_descent(10)\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7787483414418399"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction: take a model (theta) and a single example (xi) and return its predicted label\n",
    "def predict(xi, theta, bias=0):\n",
    "    label = np.sign(xi @ theta + bias)\n",
    "    return label\n",
    "\n",
    "def accuracy(theta):\n",
    "    return np.sum(predict(X_test, theta) == y_test)/X_test.shape[0]\n",
    "\n",
    "accuracy(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Implement a *noisy gradient descent* algorithm.\n",
    "\n",
    "1. Calculate gradients for each example\n",
    "2. Clip the gradients to have bounded $L2$ norm\n",
    "3. Sum the clipped gradients\n",
    "4. Use the Gaussian mechanism to add noise to the sum of gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "08fb7218fda03e851c308317aac647b0",
     "grade": false,
     "grade_id": "cell-0b1fc630cdb8484b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def L2_clip(v, b):\n",
    "    norm = np.linalg.norm(v, ord=2)\n",
    "    \n",
    "    if norm > b:\n",
    "        return b * (v / norm)\n",
    "    else:\n",
    "        return v\n",
    "\n",
    "def noisy_gradient_descent(iterations, epsilon, delta):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "theta = noisy_gradient_descent(10, 1.0, 1e-5)\n",
    "print('Final accuracy:', accuracy(theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cd498649d6383404040839a1ac75d0c4",
     "grade": true,
     "grade_id": "cell-abdbebcaa40aa5f7",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST CASE\n",
    "\n",
    "assert accuracy(noisy_gradient_descent(5, 0.001, 1e-5)) < 0.76\n",
    "assert accuracy(noisy_gradient_descent(5, 1.0, 1e-5)) > 0.70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "What is the *total privacy cost* of the noisy gradient descent algorithm above, and why? Argue informally that the algorithm satisfies this privacy cost. Use sequential composition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "01db8df655fd88392405c730527f3e64",
     "grade": true,
     "grade_id": "cell-ba58f3f4ee199481",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Repeat the above, but using advanced composition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ec1e540eb29decdc214d46eeb15c6da1",
     "grade": true,
     "grade_id": "cell-c9effbc5db1e2de3",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7\n",
    "\n",
    "Implement a version of noisy gradient descent that satisfies a *total* of $(\\epsilon, \\delta)$-differential privacy. Use sequential composition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f395037ed06f9bc220e8413ebb6f6c88",
     "grade": false,
     "grade_id": "cell-a4171a5ddcc6c2b8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2865f43d86f1182e018799fdd13512a7",
     "grade": true,
     "grade_id": "cell-abd0ebcaa40aa5f7",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST CASE\n",
    "\n",
    "assert accuracy(noisy_gradient_descent(5, 0.001, 1e-5)) < 0.76\n",
    "assert accuracy(noisy_gradient_descent(5, 1.0, 1e-5)) > 0.70"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

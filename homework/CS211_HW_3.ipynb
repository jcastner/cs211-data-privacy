{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS211: Data Privacy\n",
    "## Homework 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "from unittest.mock import patch\n",
    "\n",
    "def laplace_mech(v, sensitivity, epsilon):\n",
    "    return v + np.random.laplace(loc=0, scale=sensitivity / epsilon)\n",
    "\n",
    "adult = pd.read_csv('https://github.com/jnear/cs211-data-privacy/raw/master/homework/adult_with_pii.csv')\n",
    "adult = adult.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>DOB</th>\n",
       "      <th>SSN</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Age</th>\n",
       "      <th>Workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>Education</th>\n",
       "      <th>Education-Num</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Race</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Capital Gain</th>\n",
       "      <th>Capital Loss</th>\n",
       "      <th>Hours per week</th>\n",
       "      <th>Country</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Karrie Trusslove</td>\n",
       "      <td>9/7/1967</td>\n",
       "      <td>732-14-6110</td>\n",
       "      <td>64152</td>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brandise Tripony</td>\n",
       "      <td>6/7/1988</td>\n",
       "      <td>150-19-2766</td>\n",
       "      <td>61523</td>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brenn McNeely</td>\n",
       "      <td>8/6/1991</td>\n",
       "      <td>725-59-9860</td>\n",
       "      <td>95668</td>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dorry Poter</td>\n",
       "      <td>4/6/2009</td>\n",
       "      <td>659-57-4974</td>\n",
       "      <td>25503</td>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dick Honnan</td>\n",
       "      <td>9/16/1951</td>\n",
       "      <td>220-93-3811</td>\n",
       "      <td>75387</td>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name        DOB          SSN    Zip  Age         Workclass  \\\n",
       "0  Karrie Trusslove   9/7/1967  732-14-6110  64152   39         State-gov   \n",
       "1  Brandise Tripony   6/7/1988  150-19-2766  61523   50  Self-emp-not-inc   \n",
       "2     Brenn McNeely   8/6/1991  725-59-9860  95668   38           Private   \n",
       "3       Dorry Poter   4/6/2009  659-57-4974  25503   53           Private   \n",
       "4       Dick Honnan  9/16/1951  220-93-3811  75387   28           Private   \n",
       "\n",
       "   fnlwgt  Education  Education-Num      Marital Status         Occupation  \\\n",
       "0   77516  Bachelors             13       Never-married       Adm-clerical   \n",
       "1   83311  Bachelors             13  Married-civ-spouse    Exec-managerial   \n",
       "2  215646    HS-grad              9            Divorced  Handlers-cleaners   \n",
       "3  234721       11th              7  Married-civ-spouse  Handlers-cleaners   \n",
       "4  338409  Bachelors             13  Married-civ-spouse     Prof-specialty   \n",
       "\n",
       "    Relationship   Race     Sex  Capital Gain  Capital Loss  Hours per week  \\\n",
       "0  Not-in-family  White    Male          2174             0              40   \n",
       "1        Husband  White    Male             0             0              13   \n",
       "2  Not-in-family  White    Male             0             0              40   \n",
       "3        Husband  Black    Male             0             0              40   \n",
       "4           Wife  Black  Female             0             0              40   \n",
       "\n",
       "         Country Target  \n",
       "0  United-States  <=50K  \n",
       "1  United-States  <=50K  \n",
       "2  United-States  <=50K  \n",
       "3  United-States  <=50K  \n",
       "4           Cuba  <=50K  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 (10 points)\n",
    "\n",
    "Write code to answer the query: \"how many participants have never been married?\"\n",
    "\n",
    "*Hint*: filter the `adult_data` dataframe to contain only participants who were never married, then return the  `len` of the filtered dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8f1f7e0158a3e66d86f5d3d51a7ed30f",
     "grade": false,
     "grade_id": "cell-975eb03979d78eaf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9726"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def query1():\n",
    "    return adult[adult['Marital Status'] == 'Never-married'].shape[0]\n",
    "\n",
    "query1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "674e4c2da585cbb9e92ee8a546628647",
     "grade": true,
     "grade_id": "cell-c5ba2c93a46e8c5e",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST CASE for question 1\n",
    "assert query1() == 9726"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 (5 points)\n",
    "\n",
    "In 2-5 sentences, answer the following:\n",
    "- What is the sensitivity of `query1`, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a49f719e7bbff7b4331d41682658d904",
     "grade": true,
     "grade_id": "cell-fb1c7b0533f933f7",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "The sensitivity of query1, is 1 since it is a counting query. This is because there is not a range of numbers involved in the query, but yet a simple count of those individuals who are married or not. Hence if we are looking for a certain row, the total count will either not change or at most change by 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 (10 points)\n",
    "\n",
    "Use the implementation of `laplace_mech` to produce a differentially private answer to `query1`, with `epsilon = 0.1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0e27ddd40ababa8eee863cbbeb1961b2",
     "grade": false,
     "grade_id": "cell-80d3c108ba0f75d5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9725.36587360775"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dp_query1(epsilon):\n",
    "    return laplace_mech(query1(), 1, epsilon)\n",
    "\n",
    "dp_query1(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4f93d4f28b6a3727ed76df8885baeb8a",
     "grade": true,
     "grade_id": "cell-93eab43d27806309",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST CASE for question 3\n",
    "dp_results = [dp_query1(0.1) for _ in range(100)]\n",
    "spec = [np.random.laplace(loc=9726, scale=1/0.1) for _ in range(100)]\n",
    "assert stats.wasserstein_distance(dp_results, spec) < 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 (10 points)\n",
    "\n",
    "The `pct_error` function, defined below, returns the percent relative error between an original query result and a differentially private result for the same query.\n",
    "\n",
    "Implement a function `graph_error1` that:\n",
    "\n",
    "- Calculates 1000 differentially private answers to `dp_query1`\n",
    "- Calculates the percent error for each one of these answers against the original (non-private) answer\n",
    "- Graphs the distribution of errors using a histogram\n",
    "\n",
    "*Hint*: use `plt.hist(..., bins=20)`.\n",
    "\n",
    "The given code will use your function to plot errors for `epsilon=0.1` and `epsilon=1.0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pct_error(orig, priv):\n",
    "    return np.abs(orig - priv)/orig * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e0629316da63126e9cb985ce2dd54c40",
     "grade": false,
     "grade_id": "cell-da0c198a1cf9a866",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([246., 181., 136., 136.,  84.,  70.,  54.,  24.,  29.,  12.,  10.,\n",
       "          5.,   2.,   8.,   0.,   1.,   0.,   1.,   0.,   1.]),\n",
       " array([1.68384309e-06, 5.04646094e-03, 1.00912380e-02, 1.51360151e-02,\n",
       "        2.01807922e-02, 2.52255693e-02, 3.02703464e-02, 3.53151236e-02,\n",
       "        4.03599007e-02, 4.54046778e-02, 5.04494549e-02, 5.54942320e-02,\n",
       "        6.05390091e-02, 6.55837862e-02, 7.06285633e-02, 7.56733404e-02,\n",
       "        8.07181175e-02, 8.57628946e-02, 9.08076717e-02, 9.58524488e-02,\n",
       "        1.00897226e-01]),\n",
       " <BarContainer object of 20 artists>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def graph_error1(epsilon):\n",
    "    return plt.hist([pct_error(query1(), laplace_mech(dp_query1(epsilon), 1, epsilon)) for _ in range(1000)], bins=20)\n",
    "\n",
    "graph_error1(0.1)\n",
    "graph_error1(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3361b8760594145c039d41479c981de4",
     "grade": true,
     "grade_id": "cell-eda6bc27840a9067",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [59]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     graph_error1(\u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m      6\u001b[0m args, kwargs \u001b[38;5;241m=\u001b[39m mock_hist\u001b[38;5;241m.\u001b[39mcall_args\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m stats\u001b[38;5;241m.\u001b[39mwasserstein_distance(error_spec, args[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.001\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "error_spec = 100.0 * np.abs(np.random.laplace(loc=0, scale=1, size=1000)) / query1()\n",
    "\n",
    "with patch('matplotlib.pyplot.hist') as mock_hist:\n",
    "    graph_error1(1.0)\n",
    "    \n",
    "args, kwargs = mock_hist.call_args\n",
    "assert stats.wasserstein_distance(error_spec, args[0]) < 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5 (10 points)\n",
    "\n",
    "In 2-5 sentences, answer the following:\n",
    "\n",
    "- How does the histogram of relative errors for $\\epsilon = 0.1$ differ from the one for $\\epsilon = 1.0$?\n",
    "- What do the two histograms tell you about the effect of $\\epsilon$ on relative error?\n",
    "\n",
    "**HINT**: Pay close attention to which color represents which value of $\\epsilon$!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ce2bae13a992d9010fab785450105fd6",
     "grade": true,
     "grade_id": "cell-075013c43cc4cc1d",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "The histograms differ through the small epsilon having a condensed and overall thiner set of error values whereas big epsilon is much more of a range across error values. This shows that choosing a larger epsilon has a greater effect on the relative error of the query while smaller epsilon is more than likley have less percent error. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6 (10 points)\n",
    "\n",
    "Consider `query2`, which asks how many people in the dataset are over the age of 60."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query2():\n",
    "    return len(adult[adult['Age'] > 60])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement `dp_query2`, a differentially private version of `query2` (as in question 3), and `graph_error2`, which graphs relative error for `dp_query2` (as in question 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aa2b1a0e097669458441b4208bdb099e",
     "grade": false,
     "grade_id": "cell-1c15ba7324d807a4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def dp_query2(epsilon):\n",
    "    return laplace_mech(query2(), 1, epsilon)\n",
    "\n",
    "def graph_error2(epsilon):\n",
    "    return plt.hist([pct_error(query2(), laplace_mech(dp_query2(epsilon), 1, epsilon)) for _ in range(1000)], bins=20)\n",
    "\n",
    "graph_error2(1.0)\n",
    "graph_error1(1.0) # we plot both errors for query 1 and query 2 at the same epsilon, to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "015fdbec71d505db6698ac9ebb460e18",
     "grade": true,
     "grade_id": "cell-239ae948aa08f924",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "error_spec = 100.0 * np.abs(np.random.laplace(loc=0, scale=1, size=1000)) / query2()\n",
    "\n",
    "with patch('matplotlib.pyplot.hist') as mock_hist:\n",
    "    graph_error2(1.0)\n",
    "    \n",
    "args, kwargs = mock_hist.call_args\n",
    "assert stats.wasserstein_distance(error_spec, args[0]) < 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7 (10 points)\n",
    "\n",
    "In 2-5 sentences, answer the following:\n",
    "\n",
    "- Given the graph from question 6, how does relative error differ between `dp_query1` and `dp_query2` for the same value of $\\epsilon$?\n",
    "- What property of the query causes the difference in relative errors between `dp_query1` and `dp_query2`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "36649d5ca3c4a6845f7caa5d7952d216",
     "grade": true,
     "grade_id": "cell-be5745d92a22154c",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "The relative error differs between dp_query1 and dp_query2 for the same value of epsilon because the size of the data is different thus the amount of privacy needed will also differ... For the second query the set of results is only including individuals over 60. The property that causes this disparity between the two is sequential composition, since the same query is processed many times and the total privacy is summated. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
